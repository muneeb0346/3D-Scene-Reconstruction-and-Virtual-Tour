{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25ff6b1b",
   "metadata": {},
   "source": [
    "## Point clouds using GNPL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80a79155",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n",
      "Using device: cpu\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae6e7e3bfdc34b3b87e67bb39ebcd981",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json:   0%|          | 0.00/137 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\munee\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\munee\\.cache\\huggingface\\hub\\models--vinvino02--glpn-nyu. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e0b9239e7f547929fb1c06cbd814fb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/920 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f7bc6aed9614dd296ead68c879c41c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/245M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 33 images in '../data'\n",
      "\n",
      "[1/33] Processing: 01.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\munee\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\PIL\\Image.py:3402: DecompressionBombWarning: Image size (108000000 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Saved point cloud: glpn_pointclouds\\01_glpn.ply\n",
      "\n",
      "[2/33] Processing: 02.jpg\n",
      "   Saved point cloud: glpn_pointclouds\\02_glpn.ply\n",
      "\n",
      "[3/33] Processing: 03.jpg\n",
      "   Saved point cloud: glpn_pointclouds\\03_glpn.ply\n",
      "\n",
      "[4/33] Processing: 04.jpg\n",
      "   Saved point cloud: glpn_pointclouds\\04_glpn.ply\n",
      "\n",
      "[5/33] Processing: 05.jpg\n",
      "   Saved point cloud: glpn_pointclouds\\05_glpn.ply\n",
      "\n",
      "[6/33] Processing: 06.jpg\n",
      "   Saved point cloud: glpn_pointclouds\\06_glpn.ply\n",
      "\n",
      "[7/33] Processing: 07.jpg\n",
      "   Saved point cloud: glpn_pointclouds\\07_glpn.ply\n",
      "\n",
      "[8/33] Processing: 08.jpg\n",
      "   Saved point cloud: glpn_pointclouds\\08_glpn.ply\n",
      "\n",
      "[9/33] Processing: 09.jpg\n",
      "   Saved point cloud: glpn_pointclouds\\09_glpn.ply\n",
      "\n",
      "[10/33] Processing: 10.jpg\n",
      "   Saved point cloud: glpn_pointclouds\\10_glpn.ply\n",
      "\n",
      "[11/33] Processing: 11.jpg\n",
      "   Saved point cloud: glpn_pointclouds\\11_glpn.ply\n",
      "\n",
      "[12/33] Processing: 12.jpg\n",
      "   Saved point cloud: glpn_pointclouds\\12_glpn.ply\n",
      "\n",
      "[13/33] Processing: 13.jpg\n",
      "   Saved point cloud: glpn_pointclouds\\13_glpn.ply\n",
      "\n",
      "[14/33] Processing: 14.jpg\n",
      "   Saved point cloud: glpn_pointclouds\\14_glpn.ply\n",
      "\n",
      "[15/33] Processing: 15.jpg\n",
      "   Saved point cloud: glpn_pointclouds\\15_glpn.ply\n",
      "\n",
      "[16/33] Processing: 16.jpg\n",
      "   Saved point cloud: glpn_pointclouds\\16_glpn.ply\n",
      "\n",
      "[17/33] Processing: 17.jpg\n",
      "   Saved point cloud: glpn_pointclouds\\17_glpn.ply\n",
      "\n",
      "[18/33] Processing: 18.jpg\n",
      "   Saved point cloud: glpn_pointclouds\\18_glpn.ply\n",
      "\n",
      "[19/33] Processing: 19.jpg\n",
      "   Saved point cloud: glpn_pointclouds\\19_glpn.ply\n",
      "\n",
      "[20/33] Processing: 20.jpg\n",
      "   Saved point cloud: glpn_pointclouds\\20_glpn.ply\n",
      "\n",
      "[21/33] Processing: 21.jpg\n",
      "   Saved point cloud: glpn_pointclouds\\21_glpn.ply\n",
      "\n",
      "[22/33] Processing: 22.jpg\n",
      "   Saved point cloud: glpn_pointclouds\\22_glpn.ply\n",
      "\n",
      "[23/33] Processing: 23.jpg\n",
      "   Saved point cloud: glpn_pointclouds\\23_glpn.ply\n",
      "\n",
      "[24/33] Processing: 24.jpg\n",
      "   Saved point cloud: glpn_pointclouds\\24_glpn.ply\n",
      "\n",
      "[25/33] Processing: 25.jpg\n",
      "   Saved point cloud: glpn_pointclouds\\25_glpn.ply\n",
      "\n",
      "[26/33] Processing: 26.jpg\n",
      "   Saved point cloud: glpn_pointclouds\\26_glpn.ply\n",
      "\n",
      "[27/33] Processing: 27.jpg\n",
      "   Saved point cloud: glpn_pointclouds\\27_glpn.ply\n",
      "\n",
      "[28/33] Processing: 28.jpg\n",
      "   Saved point cloud: glpn_pointclouds\\28_glpn.ply\n",
      "\n",
      "[29/33] Processing: 29.jpg\n",
      "   Saved point cloud: glpn_pointclouds\\29_glpn.ply\n",
      "\n",
      "[30/33] Processing: 30.jpg\n",
      "   Saved point cloud: glpn_pointclouds\\30_glpn.ply\n",
      "\n",
      "[31/33] Processing: 31.jpg\n",
      "   Saved point cloud: glpn_pointclouds\\31_glpn.ply\n",
      "\n",
      "[32/33] Processing: 32.jpg\n",
      "   Saved point cloud: glpn_pointclouds\\32_glpn.ply\n",
      "\n",
      "[33/33] Processing: 33.jpg\n",
      "   Saved point cloud: glpn_pointclouds\\33_glpn.ply\n",
      "\n",
      "Done. All point clouds saved in folder: glpn_pointclouds\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# !pip install -q torch torchvision torchaudio transformers numpy open3d pillow matplotlib\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "from transformers import GLPNImageProcessor, GLPNForDepthEstimation\n",
    "import open3d as o3d\n",
    "\n",
    "# -------------------------- USER SETTINGS ------------------------------\n",
    "IMAGE_FOLDER = \"../data\"          # <-- put your input images here\n",
    "OUTPUT_FOLDER = \"glpn_pointclouds\"  # where .ply files will be saved\n",
    "MAX_INPUT_HEIGHT = 480           # as in the blog (controls memory)\n",
    "\n",
    "os.makedirs(OUTPUT_FOLDER, exist_ok=True)\n",
    "\n",
    "# --------------------------- DEVICE & MODEL ----------------------------\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "feature_extractor = GLPNImageProcessor.from_pretrained(\"vinvino02/glpn-nyu\")\n",
    "model = GLPNForDepthEstimation.from_pretrained(\"vinvino02/glpn-nyu\")\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# ------------------------ HELPER FUNCTIONS -----------------------------\n",
    "def resize_to_glpn_requirements(image_pil, max_height=MAX_INPUT_HEIGHT):\n",
    "    \"\"\"\n",
    "    Resize image so that:\n",
    "    - height <= max_height\n",
    "    - height and width are multiples of 32\n",
    "    \"\"\"\n",
    "    orig_w, orig_h = image_pil.size\n",
    "\n",
    "    new_h = max_height if orig_h > max_height else orig_h\n",
    "    new_h -= (new_h % 32)\n",
    "\n",
    "    new_w = int(new_h * orig_w / orig_h)\n",
    "    diff = new_w % 32\n",
    "    new_w = new_w - diff if diff < 16 else new_w + (32 - diff)\n",
    "\n",
    "    # PIL expects (width, height)\n",
    "    image_resized = image_pil.resize((new_w, new_h))\n",
    "    return image_resized\n",
    "\n",
    "\n",
    "def depth_from_image_glpn(image_pil):\n",
    "    \"\"\"\n",
    "    Run GLPN on a PIL image and return:\n",
    "    - depth_np: HxW depth map (float32)\n",
    "    - color_cropped: PIL image cropped to match depth\n",
    "    \"\"\"\n",
    "    # 1) Resize for model\n",
    "    image_resized = resize_to_glpn_requirements(image_pil)\n",
    "\n",
    "    # 2) Prepare input\n",
    "    inputs = feature_extractor(images=image_resized, return_tensors=\"pt\").to(device)\n",
    "\n",
    "    # 3) Forward pass\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        predicted_depth = outputs.predicted_depth  # (1,1,H,W)\n",
    "\n",
    "    depth = predicted_depth.squeeze().cpu().numpy()  # H x W\n",
    "    depth = depth * 1000.0  # scale (arbitrary, but ok)\n",
    "\n",
    "    # 4) Remove border artifacts (same as blog)\n",
    "    pad = 16\n",
    "    depth_cropped = depth[pad:-pad, pad:-pad]\n",
    "\n",
    "    # 5) Crop the RGB image correspondingly\n",
    "    w_resized, h_resized = image_resized.size\n",
    "    color_cropped = image_resized.crop(\n",
    "        (pad, pad, w_resized - pad, h_resized - pad)\n",
    "    )\n",
    "\n",
    "    return depth_cropped.astype(np.float32), color_cropped\n",
    "\n",
    "\n",
    "def depth_to_pointcloud_open3d(depth_image, color_image=None):\n",
    "    \"\"\"\n",
    "    Convert depth (HxW) and optional color (PIL, same size) into an Open3D point cloud.\n",
    "    Intrinsics are synthetic but consistent across images.\n",
    "    \"\"\"\n",
    "    depth_np = depth_image\n",
    "    h, w = depth_np.shape\n",
    "\n",
    "    # Camera intrinsics (rough pinhole model)\n",
    "    fx = fy = max(h, w)  # arbitrary but reasonable focal\n",
    "    cx = w / 2.0\n",
    "    cy = h / 2.0\n",
    "\n",
    "    intrinsic = o3d.camera.PinholeCameraIntrinsic(\n",
    "        width=w,\n",
    "        height=h,\n",
    "        fx=fx,\n",
    "        fy=fy,\n",
    "        cx=cx,\n",
    "        cy=cy\n",
    "    )\n",
    "\n",
    "    # Open3D expects depth scale in meters; here we keep as-is\n",
    "    depth_o3d = o3d.geometry.Image(depth_np)\n",
    "\n",
    "    if color_image is not None:\n",
    "        color_resized = color_image.resize((w, h))\n",
    "        color_np = np.asarray(color_resized).astype(np.uint8)\n",
    "    else:\n",
    "        color_np = np.zeros((h, w, 3), dtype=np.uint8)\n",
    "\n",
    "    color_o3d = o3d.geometry.Image(color_np)\n",
    "\n",
    "    rgbd = o3d.geometry.RGBDImage.create_from_color_and_depth(\n",
    "        color_o3d,\n",
    "        depth_o3d,\n",
    "        depth_scale=1.0,       # already in arbitrary units\n",
    "        depth_trunc=float(depth_np.max()) * 1.05,\n",
    "        convert_rgb_to_intensity=False\n",
    "    )\n",
    "\n",
    "    pcd = o3d.geometry.PointCloud.create_from_rgbd_image(\n",
    "        rgbd,\n",
    "        intrinsic\n",
    "    )\n",
    "\n",
    "    # Flip to match Open3D coordinate convention (optional but standard)\n",
    "    pcd.transform([[1, 0, 0, 0],\n",
    "                   [0,-1, 0, 0],\n",
    "                   [0, 0,-1, 0],\n",
    "                   [0, 0, 0, 1]])\n",
    "\n",
    "    return pcd\n",
    "\n",
    "# -------------------------- MAIN LOOP ----------------------------------\n",
    "image_paths = sorted(\n",
    "    glob.glob(os.path.join(IMAGE_FOLDER, \"*.jpg\")) +\n",
    "    glob.glob(os.path.join(IMAGE_FOLDER, \"*.jpeg\")) +\n",
    "    glob.glob(os.path.join(IMAGE_FOLDER, \"*.png\"))\n",
    ")\n",
    "\n",
    "if not image_paths:\n",
    "    raise RuntimeError(f\"No images found in folder: {IMAGE_FOLDER}\")\n",
    "\n",
    "print(f\"Found {len(image_paths)} images in '{IMAGE_FOLDER}'\")\n",
    "\n",
    "for idx, img_path in enumerate(image_paths):\n",
    "    print(f\"\\n[{idx+1}/{len(image_paths)}] Processing:\", os.path.basename(img_path))\n",
    "\n",
    "    img = Image.open(img_path).convert(\"RGB\")\n",
    "\n",
    "    # 1) Get depth map from GLPN\n",
    "    depth, color_crop = depth_from_image_glpn(img)\n",
    "\n",
    "    # 2) Convert to point cloud\n",
    "    pcd = depth_to_pointcloud_open3d(depth, color_crop)\n",
    "\n",
    "    # 3) Save as .ply\n",
    "    base = os.path.splitext(os.path.basename(img_path))[0]\n",
    "    out_path = os.path.join(OUTPUT_FOLDER, f\"{base}_glpn.ply\")\n",
    "    o3d.io.write_point_cloud(out_path, pcd)\n",
    "    print(\"   Saved point cloud:\", out_path)\n",
    "\n",
    "print(\"\\nDone. All point clouds saved in folder:\", OUTPUT_FOLDER)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
